{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Basic\n",
        "\n",
        "PyTorch는 머신 러닝 라이브러리로, 주로 딥 러닝 알고리즘을 구현하고 실험하기 위해 사용됩니다. PyTorch는 Python 기반으로, 다양한 머신 러닝 및 딥 러닝 알고리즘의 개발과 연구를 용이하게 하기 위해 설계되었습니다. 이 라이브러리는 쉽게 사용하고 확장할 수 있는 구조를 제공하여 연구자와 개발자 모두에게 유용합니다.\n",
        "\n",
        "[PyTorch Homepage](https://pytorch.org/)\n",
        "\n",
        "![PyTorch Logo](https://github.com/jphan32/CVTrack-Tutorials/blob/main/resources/pytorch.png?raw=true)\n",
        "\n",
        "### PyTorch의 주요 특징\n",
        "#### 동적 계산 그래프(Dynamic Computational Graph)\n",
        "- PyTorch는 동적 계산 그래프를 사용하여, 연산을 진행하는 동안 그래프를 구축합니다. 이는 개발자에게 높은 유연성을 제공하며, 디버깅도 용이합니다.\n",
        "\n",
        "#### 자동 미분(Automatic Differentiation)\n",
        "- PyTorch의 autograd 시스템은 연산 그래프를 통해 자동 미분을 수행하여 그래디언트를 계산합니다. 이는 복잡한 네트워크에서도 역전파를 쉽게 구현할 수 있게 해줍니다.\n",
        "\n",
        "#### 다양한 라이브러리와 도구\n",
        "- PyTorch는 torchvision, torchaudio, torchtext 등 다양한 도메인 특화 라이브러리를 제공하여, 다양한 애플리케이션에 적용할 수 있습니다.\n",
        "\n",
        "#### 커뮤니티와 지원\n",
        "- PyTorch는 강력한 커뮤니티 지원을 받고 있으며, 다양한 튜토리얼과 예제를 통해 빠르게 학습하고 응용할 수 있습니다.\n",
        "\n",
        "#### 확장성\n",
        "- PyTorch는 쉽게 사용자 정의 연산을 추가하고, GPU 가속을 활용할 수 있어, 확장성이 높습니다.\n",
        "---"
      ],
      "metadata": {
        "id": "9LfMm-qhUh6M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 간단한 선형 회귀 모델 구현해보기\n",
        "- 목표 : 캘리포니아 주택 가격 예측\n",
        "- 데이터 : Colab 샘플 데이터"
      ],
      "metadata": {
        "id": "35ZKp32OXfNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 라이브러리 Import\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "from scipy import stats\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "XyeOOABQX2FC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 데이터 불러오기 & EDA\n",
        "\n",
        "# CSV 파일에서 데이터 불러오기\n",
        "df_csv = pd.read_csv('sample_data/california_housing_train.csv')\n",
        "\n",
        "# 결측치 제거\n",
        "df_csv = df_csv.dropna(inplace=True)\n",
        "\n",
        "# Z-score를 이용한 이상치 제거\n",
        "z_scores = stats.zscore(df_csv[['median_income', 'median_house_value']])\n",
        "abs_z_scores = np.abs(z_scores)\n",
        "filtered_entries = (abs_z_scores < 3).all(axis=1)\n",
        "df_csv = df_csv[filtered_entries]\n",
        "\n",
        "# 상관 분석\n",
        "correlation_matrix = df_csv.corr()\n",
        "sns.heatmap(data=correlation_matrix, annot=True)\n",
        "plt.show()\n",
        "\n",
        "# 산점도 그래프\n",
        "sns.scatterplot(data=df_csv, x='median_income', y='median_house_value')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bwe4E8x6XpUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 데이터 정의\n",
        "\n",
        "# 데이터 정규화: MinMaxScaler를 사용하여 스케일링\n",
        "scaler = MinMaxScaler()\n",
        "df_csv[['median_income', 'median_house_value']] = scaler.fit_transform(df_csv[['median_income', 'median_house_value']])\n",
        "\n",
        "# 특성과 레이블 선택\n",
        "x = df_csv[['median_income']].values\n",
        "y = df_csv[['median_house_value']].values\n",
        "\n",
        "# 데이터 분할\n",
        "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# 텐서 변환\n",
        "x_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
        "x_val_tensor = torch.tensor(x_val, dtype=torch.float32)\n",
        "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
        "\n",
        "# 데이터셋과 데이터 로더 준비\n",
        "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
        "val_dataset = TensorDataset(x_val_tensor, y_val_tensor)\n",
        "\n",
        "batch_size = 2000\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "HSBltlNxa9i_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 모델 정의\n",
        "\n",
        "class LinearRegression(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LinearRegression, self).__init__()\n",
        "        # 선형 계층 정의 (입력 차원, 출력 차원)\n",
        "        self.linear = nn.Linear(1, 1)  # median_income은 1차원, median_house_value도 1차원\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "model = LinearRegression()"
      ],
      "metadata": {
        "id": "NeaLw1JLYh1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 손실 함수와 옵티마이저 정의\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "LLbUpVwIZYvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 선형회귀 모델 학습\n",
        "\n",
        "# epoch 설정\n",
        "num_epochs = 1000\n",
        "\n",
        "# Early Stopping을 위한 변수 초기화\n",
        "early_stopping_patience = 5\n",
        "early_stopping_counter = 0\n",
        "best_loss = float('inf')\n",
        "\n",
        "# 학습\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0  # 에폭에 대한 총 손실 초기화\n",
        "\n",
        "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
        "        # 순전파\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        # 역전파\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()  # 배치의 손실 누적\n",
        "\n",
        "    # 에포크당 평균 손실 계산 및 출력\n",
        "    avg_train_loss = total_loss / len(train_loader)\n",
        "\n",
        "    # 검증 데이터셋에 대한 평가\n",
        "    model.eval()\n",
        "    total_val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for features, targets in val_loader:\n",
        "            predictions = model(features)\n",
        "            val_loss = criterion(predictions, targets)\n",
        "            total_val_loss += val_loss.item()\n",
        "\n",
        "    # 에포크당 평균 검증 손실 계산\n",
        "    avg_val_loss = total_val_loss / len(val_loader)\n",
        "\n",
        "    # Early Stopping 체크\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.6f}, Validation Loss: {avg_val_loss:.6f}')\n",
        "    if avg_val_loss < best_loss:\n",
        "        best_loss = avg_val_loss\n",
        "        early_stopping_counter = 0  # 최고 기록 갱신 시 카운터 초기화\n",
        "    else:\n",
        "        early_stopping_counter += 1  # 기록 갱신 못할 시 카운터 증가\n",
        "\n",
        "    if early_stopping_counter >= early_stopping_patience:\n",
        "        print(f'Early stopping triggered after epoch {epoch+1}')\n",
        "        break"
      ],
      "metadata": {
        "id": "T-t1DLGpaG9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 테스트 데이터셋 평가 및 결과 시각화\n",
        "- 목표 : 캘리포니아 주택 가격 예측\n",
        "- 데이터 : Colab 샘플 데이터"
      ],
      "metadata": {
        "id": "hC3QdxkvxPOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 데이터셋 불러오기\n",
        "df_test_csv = pd.read_csv('sample_data/california_housing_test.csv')\n",
        "\n",
        "# 결측치가 있다면 제거\n",
        "df_test_csv.dropna(inplace=True)\n",
        "\n",
        "# 데이터 정규화: MinMaxScaler를 사용하여 스케일링\n",
        "# 학습 데이터에 대해 이미 fit이 수행된 scaler를 사용해야 하므로,\n",
        "# 테스트 데이터에는 fit_transform 대신 transform을 적용합니다.\n",
        "# 가정: 'scaler'는 학습 데이터에 대해 이미 fit 되었습니다.\n",
        "df_test_csv[['median_income', 'median_house_value']] = scaler.transform(df_test_csv[['median_income', 'median_house_value']])\n",
        "\n",
        "# 텐서 변환\n",
        "x = df_csv[['median_income']].values\n",
        "y = df_csv[['median_house_value']].values\n",
        "x_test_tensor = torch.tensor(x, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "# 데이터셋과 데이터 로더 준비\n",
        "test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n",
        "batch_size = 2000\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size)\n",
        "\n",
        "\n",
        "# 테스트 데이터셋에 대한 평가\n",
        "model.eval()\n",
        "\n",
        "# 예측값을 저장할 리스트 초기화\n",
        "predictions, actuals = [], []\n",
        "\n",
        "# 테스트 데이터에 대한 예측 수행\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        y_test_pred = model(X_batch)\n",
        "        predictions.append(y_test_pred.numpy())\n",
        "        actuals.append(y_batch.numpy())"
      ],
      "metadata": {
        "id": "oT32ymF-xF8m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}